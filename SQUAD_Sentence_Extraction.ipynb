{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SQUAD-Sentence-Extraction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/collarad/learning-bert/blob/master/SQUAD_Sentence_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2_TaWkHL2TG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/collarad/learning-bert.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd7RbLvQOaF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/learning-bert/datasets/squad20/dev-v2.0.zip -d /content/learning-bert/datasets/squad20/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeZNj5FmbiCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%ls learning-bert/datasets/squad20/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7apnrBDPqJ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "0fe3b8ba-48bc-431a-a83f-fc7efbe9c22f"
      },
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.1.4)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.6.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.2)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.0.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.16.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.2->spacy) (4.28.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYZpHbQ9O-vw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZcN7sLLP1BO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0x3QEu1oEEw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "31b973d8-4249-4f8a-ddc2-d81aa475ac92"
      },
      "source": [
        "#Testing spaCy method to split a paragraph into sentences\n",
        "text = '3. English law takes a dim view of stealing stuff from the shops. Some may argue that this is a pity.'\n",
        "doc = nlp(text)\n",
        "for sent in doc.sents:\n",
        "    print(\"****\", sent.start)\n",
        "    print(\"****\", sent.text)\n",
        "    print(\"****\", sent.end)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**** 0\n",
            "**** 3.\n",
            "**** 2\n",
            "**** 2\n",
            "**** English law takes a dim view of stealing stuff from the shops.\n",
            "**** 15\n",
            "**** 15\n",
            "**** Some may argue that this is a pity.\n",
            "**** 24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amo_LuidqtaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/learning-bert/datasets/squad20/dev-v2.0.json\",'rb') as f:\n",
        "    j = json.load(f)\n",
        "\n",
        "numberOfData = len(j['data'])\n",
        "print(numberOfData)\n",
        "#paragraphs = j['data'][0]['paragraphs']\n",
        "    \n",
        "#TODO I do not like to many fors but due to time constraints this remains as a todo task\n",
        "for dataItem in j['data']:\n",
        "    print(dataItem['title'])\n",
        "    countErrors = 1\n",
        "    #Iterating Paragraphs in Data\n",
        "    for paragraph in dataItem['paragraphs']:\n",
        "      context = paragraph['context']\n",
        "      #print(len(context))\n",
        "      #Spliting the context in setences using spaCy\n",
        "      doc = nlp(context)\n",
        "      #Iterating all questions to find the sentence\n",
        "      for qa in paragraph['qas']:\n",
        "        try:\n",
        "          firstAnswer = qa['answers'][0]['text']\n",
        "          print(\"Answer: \"+firstAnswer)\n",
        "          for sent in doc.sents:\n",
        "            if firstAnswer in sent.text:\n",
        "              print(\"****\", sent.text)\n",
        "        except:\n",
        "          countErrors = countErrors + 1\n",
        "          #print('Error getting the answer text')\n",
        "        \n",
        "        \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}